{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scratch Implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.89</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.12</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.82</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.42</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.94</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>6.93</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>5.89</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>7.21</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>7.63</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>6.22</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cgpa  package\n",
       "0    6.89     3.26\n",
       "1    5.12     1.98\n",
       "2    7.82     3.25\n",
       "3    7.42     3.67\n",
       "4    6.94     3.57\n",
       "..    ...      ...\n",
       "195  6.93     2.46\n",
       "196  5.89     2.57\n",
       "197  7.21     3.24\n",
       "198  7.63     3.96\n",
       "199  6.22     2.33\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('placement.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Cost function\n",
    "def cost_function(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = sigmoid(X @ theta)\n",
    "    cost = (1 / m) * (-y.T @ np.log(h) - (1 - y).T @ np.log(1 - h))\n",
    "    gradient = (1 / m) * X.T @ (h - y)\n",
    "    return cost, gradient\n",
    "\n",
    "# Gradient descent\n",
    "def gradient_descent(X, y, theta, learning_rate, iterations):\n",
    "    cost_history = []\n",
    "    for _ in range(iterations):\n",
    "        cost, gradient = cost_function(X, y, theta)\n",
    "        theta -= learning_rate * gradient\n",
    "        cost_history.append(cost)\n",
    "    return theta, cost_history\n",
    "\n",
    "# Prepare the data\n",
    "X = df['cgpa'].values.reshape(-1, 1)\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X))  # Add intercept term\n",
    "# num_rows in X := X.shape[0]\n",
    "y = (df['package'] > 3).astype(int)  # Convert package to binary labels\n",
    "\n",
    "# Initialize theta and hyperparameters\n",
    "theta = np.zeros(X.shape[1])\n",
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "# Train the model\n",
    "theta, cost_history = gradient_descent(X, y, theta, learning_rate, iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CGPA  Predicted Output  Actual Output\n",
      "0    6.89                 1              1\n",
      "1    5.12                 0              0\n",
      "2    7.82                 1              1\n",
      "3    7.42                 1              1\n",
      "4    6.94                 1              1\n",
      "..    ...               ...            ...\n",
      "195  6.93                 1              0\n",
      "196  5.89                 1              0\n",
      "197  7.21                 1              1\n",
      "198  7.63                 1              1\n",
      "199  6.22                 1              0\n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "predictions = sigmoid(X @ theta)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Create DataFrame for predicted and actual output\n",
    "results_df = pd.DataFrame({\n",
    "    'CGPA': df['cgpa'],\n",
    "    'Predicted Output': predicted_labels,\n",
    "    'Actual Output': y\n",
    "})\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Predicted Positive  Predicted Negative\n",
      "Actual Positive                  98                   0\n",
      "Actual Negative                  89                  13\n"
     ]
    }
   ],
   "source": [
    "# Initialize counts\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "# Iterate through rows of the DataFrame\n",
    "for index, row in results_df.iterrows():\n",
    "    actual = row['Actual Output']\n",
    "    predicted = row['Predicted Output']\n",
    "    \n",
    "    if actual == 1 and predicted == 1:\n",
    "        TP += 1\n",
    "    elif actual == 0 and predicted == 0:\n",
    "        TN += 1\n",
    "    elif actual == 0 and predicted == 1:\n",
    "        FP += 1\n",
    "    elif actual == 1 and predicted == 0:\n",
    "        FN += 1\n",
    "\n",
    "# Create the confusion matrix DataFrame\n",
    "confusion_matrix = pd.DataFrame({\n",
    "    'Predicted Positive': [TP, FP],\n",
    "    'Predicted Negative': [FN, TN]\n",
    "}, index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score is usually more useful, than accuracy especially if you have an uneven sample distribution. \n",
    "Accuracy work best If \"FP\" & \"FN\" have similar cost\n",
    "\n",
    "If FP & FN very different better to look at \"Precision\" & \"Recall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Metric     Value\n",
      "0   Accuracy  0.555000\n",
      "1  Precision  0.524064\n",
      "2     Recall  1.000000\n",
      "3   F1 Score  0.687719\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "# Calculate Precision\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "# Calculate Recall\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Display the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1_score]\n",
    "})\n",
    "\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using Library Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CGPA  Predicted Output  Actual Output\n",
      "0    6.89                 0              1\n",
      "1    5.12                 0              0\n",
      "2    7.82                 1              1\n",
      "3    7.42                 1              1\n",
      "4    6.94                 1              1\n",
      "..    ...               ...            ...\n",
      "195  6.93                 1              0\n",
      "196  5.89                 0              0\n",
      "197  7.21                 1              1\n",
      "198  7.63                 1              1\n",
      "199  6.22                 0              0\n",
      "\n",
      "[200 rows x 3 columns]\n",
      "      Metric     Value\n",
      "0   Accuracy  0.810000\n",
      "1  Precision  0.772727\n",
      "2     Recall  0.867347\n",
      "3   F1 Score  0.817308\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('placement.csv')\n",
    "\n",
    "# Prepare the data\n",
    "X = df['cgpa'].values.reshape(-1, 1)\n",
    "y = (df['package'] > 3).astype(int)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Create DataFrame for predicted and actual output\n",
    "results_df = pd.DataFrame({\n",
    "    'CGPA': df['cgpa'],\n",
    "    'Predicted Output': predictions,\n",
    "    'Actual Output': y\n",
    "})\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "# Calculate evaluation metrics using library functions\n",
    "conf_matrix = confusion_matrix(y, predictions)\n",
    "accuracy = accuracy_score(y, predictions)\n",
    "precision = precision_score(y, predictions)\n",
    "recall = recall_score(y, predictions)\n",
    "f1 = f1_score(y, predictions)\n",
    "\n",
    "# Display the metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "    'Value': [accuracy, precision, recall, f1]\n",
    "})\n",
    "\n",
    "print(metrics_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
